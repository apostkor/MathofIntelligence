{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Math of Intelligence Step #6\n",
    "\n",
    "## by PARK-SI HYUNG. 2019-01-18.\n",
    "---\n",
    "# # DEEP Q LEARNING\n",
    "> 컴퓨터가 스스로 마리오를 플레이하게 해봅시다\n",
    "\n",
    "# WHAT IS REINFORCEMENT LEARNING ?\n",
    "\n",
    "#### 알려지지 않은 환경에서 ACTION을 수행하며 얻는 REWARD를 통해 학습하는 과정\n",
    "#### LABEL 대신 REWARD를 사용해 극대화 시키는 방향으로 갑니다\n",
    "#### 이상적인 학습 과정을 통해 환경에 대한 반응으로부터 목표를 찾아갑니다\n",
    "#### 학습을 배우는 주체가 특정 시점의 상태이며, 이에 대한 행동을 학습하는 방법입니다\n",
    "#### 비지도학습과 다르게 FEEDBACK이 존재합니다\n",
    "---\n",
    "\n",
    "![JPEG](http://solarisailab.com/wp-content/uploads/2015/11/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5.jpg)\n",
    "#   \n",
    "# Q - LEARNING\n",
    "\n",
    "> 주어진 상태에서 특정 행동의 QUALITY(Q)를 찾습니다\n",
    "\n",
    "![JPEG](https://i.imgur.com/hdDIdqh.png)\n",
    "\n",
    "- 강화학습의 목표는 게임이 끝난 시점에서의 최고 점수를 얻는 POLICY를 찾아야합니다\n",
    "- 가장 높은 QUALITY(Q)를 구하기 위해 Q-VECTOR를 랜덤하게 초기화한 후, 훈련을 시키면서\n",
    "- 어떠한 ACTION을 취하는지에 따라 REWARD와 STATE가 달라지기 때문에 E\n",
    "    \n",
    "![JPEG](https://i.imgur.com/cd5VCo0.png)\n",
    "\n",
    "- 가장 큰 REWARD를 반환하는 Q를 찾습니다\n",
    "- 가장 높은 Q를 구하기 위해 BELLMAN EXPECTATION EQUATION을 사용합니다\n",
    "\n",
    "\n",
    "![JPEG](https://i.imgur.com/q2WWHHH.png)\n",
    "#   \n",
    "\n",
    "# DEEP-Q LEARNING EXAMPLE\n",
    "#   \n",
    "![GIF](https://thumbs.gfycat.com/AdorableRadiantFerret-size_restricted.gif)\n",
    "#   \n",
    "![GIF](https://media.giphy.com/media/xSi0vyq0FI6Os/giphy.gif)\n",
    "\n",
    "\n",
    "\n",
    "#  \n",
    "#  \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # GENETIC ALGORITHM IN A.I\n",
    "> 진화의 원리를 모방하여 문제해결에 사용하는 최적화 방법입니다\n",
    "\n",
    "> 최적화 방법은 주어진 문제상황에서 실현가능한 해들 중 가장 좋은 해를 찾습니다\n",
    "\n",
    "\n",
    "![JPEG](https://i.imgur.com/gCSPCl0.png)\n",
    "### - CROSSOVER : 2개의 염색체 교배를 통해 새로운 개체를 발생시킵니다\n",
    "### - MUTATE : 좋은 유전자 발견의 가능성을 열어둡니다\n",
    "\n",
    "# USE CASES - 어디에 사용되는가\n",
    "\n",
    "- POTENTIAL SOLUTION 문제에 적합합니다\n",
    "- LARGE MULTI-DIMENSIONAL SPACE에서 불분명한 정답을 찾아야할 때\n",
    "- GOOD SOLUTION은 많으나 완벽한 한가지의 SOLUTION이 필요할 때\n",
    "\n",
    "#  \n",
    "#  \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # QUANTUM ALGORITHM\n",
    "![JPEG](https://i.imgur.com/nYbaJ83.png)\n",
    "\n",
    "### 최소 정보 단위를 BIT가 아닌 MATRIX로 표현하고 이에 대하여 BOOLEAN <BR>연산이 아닌 LINEAR ALGEBRA 연산을 함으로써 대량 정보에 대한 <BR>연산량을 O(√x)로 만듭니다\n",
    "\n",
    "---\n",
    "\n",
    "# 기존의 방식\n",
    "- STORE NUMBERS (MEMORY)\n",
    "- PROCESS NUMBERS (COMPUTATION)\n",
    "\n",
    "---   \n",
    "\n",
    "# QUBIT\n",
    "> 0과 1 둘중 하나를 가지는 BIT와 다르게 0과 1을 동시에 가질 수 있습니다\n",
    "\n",
    "- SUPERPOSITION : 0과 1뿐만 아니라 0과 1 사이에 있는 어떠한 숫자도 가능합니다\n",
    "- ENTANGLEMENT : QUBIT은 서로 결합될 수 있는 성질을 가지고 있습니다\n",
    "#   \n",
    "![JPEG](https://www.autodesk.com/products/eagle/blog/wp-content/uploads/2017/05/qubit.png)\n",
    "#    \n",
    "# QUBIT의 좌표적 성질\n",
    "- QUBIT은 무한한 양의 정보를 포함하고 있습니다\n",
    "- QUBIT의 좌표적 성질은 무한한 SEQUENCE의 DIGIT을 인코딩할 수 있습니다\n",
    "\n",
    "![JPEG](https://s.hswstatic.com/gif/quantum-computer-2.jpg)\n",
    "#  \n",
    "#  \n",
    "#  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
