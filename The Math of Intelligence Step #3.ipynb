{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Math of Intelligence Step #3\n",
    "\n",
    "## by PARK-SI HYUNG. 2019-01-15.\n",
    "---\n",
    "# # DIMENSIONALITY REDUCTION\n",
    "\n",
    "\n",
    ">PCA(PRINCIPAL COMPONENT ANALYSIS)의 목적\n",
    "- 데이터에서 패턴을 찾는것 \n",
    "- 변수들 사이에 강한 상관관계만 존재한다면 차원을 축소하는게 순조로워집니다\n",
    "- 우리가 필요한 것은 상관관계를 가진 변수들을 찾아 1차원으로 만드는 것입니다\n",
    "\n",
    "![JPEG](http://www.nlpca.org/fig-pca-principal-component-analysis-m.png)\n",
    "\n",
    "### HIGH DIMENSIONAL DATA는 처리하기가 까다롭습니다\n",
    "- 차원의 저주 ! 고차원의 데이터는 시간도 오래걸리고 데이터의 양이 기하급수적으로 증가합니다\n",
    "- 오버피팅의 문제\n",
    "- 모든 변수들이 필요하진 않다, 우리가 필요한 변수만 골라내자\n",
    "- 차원을 줄이면 노이즈도 줄일 수 있다\n",
    "\n",
    "### FEATURE SELECTION\n",
    "- 우리에게 필요한 FEATURE들을 선택하는게 가장 중요합니다\n",
    "- 예를들어 타이타닉의 생존자를 예측하는데 수많은 FEATURE이 있겠지만\n",
    "- 성별, 나이, 1등석 등 변수들이 짐 무게, 탑승 항구 같은 변수보다 중요할 수 있습니다\n",
    "\n",
    "### FEATURE EXTRACTION\n",
    "- FEATURE를 선택하는것도 중요하지만 새로운 FEATURE를 만들어 내는것 또한 중요합니다\n",
    "- 이름의 Mr, Mrs, MASTER 등을 가지고 새로운 이니셜 FEATURE를 만들어 낼 수도 있고\n",
    "- 나이를 10~20, 20~30를 기준으로 AGE_CATEGORY를 만들 수도 있습니다\n",
    "---\n",
    "# VARIANCE MAXIMIZE (분산 최대화)\n",
    "> PCA는 분산을 최대화 하는 과정입니다 (분산 : 데이터가 서로 얼마나 떨어져있는지)\n",
    "\n",
    "- 분산을 최대화 함으로써 각 벡터들이 독립적인 역할을 수행하도록 해줍니다\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 데이터셋을 불러옵니다\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "    header=None, \n",
    "    sep=',')\n",
    "\n",
    "# 5개의 column만 골라옵니다\n",
    "df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    "# 결측치는 모두 없애줍니다\n",
    "df.dropna(how=\"all\", inplace=True) # drops the empty line at file-end\n",
    "\n",
    "# X에는 SEPAL_LEN, SEPAL_WID, PETAL_LEN, PETAL_WIN 칼럼을 넣어주고\n",
    "# Y에는 CLASS 칼럼을 넣어줍니다 (LABEL)\n",
    "X = df.iloc[:,0:4].values\n",
    "y = df.iloc[:,4].values\n",
    "\n",
    "# df에는 각 50개의 Iris-setosa, Iris-versicolor, Iris-virginica가 분포합니다\n",
    "# 히스토그램을 그려 이들의 sepal length, width, petal length, width를 알아봅시다\n",
    "label_dict = {1: 'Iris-Setosa',\n",
    "              2: 'Iris-Versicolor',\n",
    "              3: 'Iris-Virgnica'}\n",
    "\n",
    "feature_dict = {0: 'sepal length [cm]',\n",
    "                1: 'sepal width [cm]',\n",
    "                2: 'petal length [cm]',\n",
    "                3: 'petal width [cm]'}\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    # 그래프 사이즈를 8X6으로 지정\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # 총 4개의 그래프를 순서대로 출력\n",
    "    for cnt in range(4):\n",
    "        # 가로 2개, 세로 2개의 그래프를 그립니다\n",
    "        plt.subplot(2, 2, cnt+1)\n",
    "        for lab in ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'):\n",
    "            plt.hist(X[y==lab, cnt],\n",
    "                     label=lab,\n",
    "                     bins=10,\n",
    "                     alpha=0.3,)\n",
    "        plt.xlabel(feature_dict[cnt])\n",
    "    plt.legend(loc='upper right', fancybox=True, fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVARIANCE MATRIX\n",
    "\n",
    "> PCA를 하기 위해 공분산을 구해봅시다. <BR>공분산이란 데이터가 얼마나 떨어져있는지 나타냅니다\n",
    "\n",
    "### 공분산 공식\n",
    "![JPEG](https://render.githubusercontent.com/render/math?math=%5CSigma%20%3D%20%5Cfrac%7B1%7D%7Bn-1%7D%20%5Cleft%28%20%28%5Cmathbf%7BX%7D%20-%20%5Cmathbf%7B%5Cbar%7Bx%7D%7D%29%5ET%5C%3B%28%5Cmathbf%7BX%7D%20-%20%5Cmathbf%7B%5Cbar%7Bx%7D%7D%29%20%5Cright%29&mode=inline)\n",
    "---\n",
    "### 하지만 공분산에도 문제가 하나있습니다. 단위의 크기에 영향을 받습니다\n",
    "- 이점을 보완하기 위해 상관계수로 나타내 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix\n",
      "[[ 1.00671141 -0.11010327  0.87760486  0.82344326]\n",
      " [-0.11010327  1.00671141 -0.42333835 -0.358937  ]\n",
      " [ 0.87760486 -0.42333835  1.00671141  0.96921855]\n",
      " [ 0.82344326 -0.358937    0.96921855  1.00671141]]\n"
     ]
    }
   ],
   "source": [
    "# 위에서 구한 X데이터를 가지고 PCA를 해봅시다\n",
    "# X데이터에는 150개 꽃의 'sepal_len', 'sepal_wid', 'petal_len', 'petal_wid'\n",
    "# 4종류의 데이터가 분포하고 있습니다 (150X4, 600개의 데이터)\n",
    "# PCA를 위해 표본공분산을 구해봅시다. 표본공분산이란 데이터가 얼마나 떨어져있는지 나타냅니다\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "# 평균이 0이고 표준쳔차가 1인 변수들로 바꿔줍니다\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "# 평균을 구합니다\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "\n",
    "# 위의 공식을 대입해 공분산을 구해봅니다\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "print('Covariance matrix')\n",
    "print(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff9d96f19b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 공분산보다는 상관관계가 더 직관적입니다\n",
    "# 히트맵을 그려서 4개 변수의 상관관계를 알아봅시다\n",
    "cov, s, v = np.linalg.svd(X_std.T)\n",
    "\n",
    "# 공분산을 DatFrame에 넣어줍시다\n",
    "df = pd.DataFrame(cov, columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid'],\n",
    "                  index= ['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid'])\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "heatmap_data = df\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Correlation Between features', size=15, y=1.1)\n",
    "sns.heatmap(heatmap_data.astype(float).corr(), linewidths=0.1, vmax=1.0,\n",
    "           square=True, cmap=colormap, linecolor='white', annot=True, annot_kws={\"size\": 16})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "#   \n",
    "#   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # RECURRENT NEURAL NETWORK\n",
    "\n",
    "> 과거의 데이터가 미래에 영향을 줄 수 있는 신경망\n",
    "---\n",
    "\n",
    "# WHAT IS RNN ?\n",
    "![JPEG](https://cdn-images-1.medium.com/max/1600/1*hbpW6FRw7mrc607fwM9rKw.gif)\n",
    "\n",
    "\n",
    "- 우리가 앞에서 봤던 NEURAL NETWORK는 항상 같은 결과를 반환합니다\n",
    "- 메모리가 없기 때문에 입력할 때 마다 초기화 되기 때문입니다\n",
    "- 이번에는 NETWORK 안에 상태(STATE)를 추가해 과거의 데이터가 \n",
    "- 미래에 영향을 줄 수 있는 신경망을 만들어 봅니다\n",
    "- 예를들어 I am hungr에서 다음 글자로 y가 오는 것을 예측할 수 있습니다\n",
    "\n",
    "![JPEG](https://cdn-images-1.medium.com/max/1600/1*NKhwsOYNUT5xU7Pyf6Znhg.png)\n",
    "\n",
    "## 위 그림처럼 하나의 네트워크가 여러개 복사된 형태를 띕니다\n",
    "## 각각의 네트워크는 다음 단계로 정보를 넘겨줍니다\n",
    "---\n",
    "## 어디에 유용할까 ?\n",
    "- Time Series Prediction(시계열 데이터) : 날씨, 주가, 교통량 예측\n",
    "- Sequential Data Generation(순차 데이터) : 음악, 영상, 음성생성 및 자동완성\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "# RNN LOSS FUNCTION\n",
    "\n",
    "### LOSS FUNCTION으로는 PROBABILITY(확률)을 사용합니다\n",
    "![JPEG](https://camo.githubusercontent.com/415f2e709cbf1316fb8b10c30bdef44eb9ff42a8/687474703a2f2f692e696d6775722e636f6d2f4c6c494d76656b2e706e67)\n",
    "- 다음에 예상되는 문자와 TARGET 문자를 비교해 오차를 계산합니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 137628, 80 unique\n"
     ]
    }
   ],
   "source": [
    "# 카프카의 소설을 이용해 훈련시켜봅시다\n",
    "data = open('kafka.txt', 'r').read()\n",
    "\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has {}, {} unique'.format(data_size, vocab_size))\n",
    "\n",
    "# encode와 decode할 딕셔너리를 2개 만듭니다\n",
    "# encode는 데이터를 부호화 하는것이고(숫자로), decode는 그것을 해제하는 것 입니다\n",
    "# char 데이터를 index로 변환\n",
    "char_to_ix = {ch : i for i, ch in enumerate(chars)}\n",
    "# index를 char 데이터로 변환\n",
    "ix_to_char = {i : ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# a가 들어있는 숫자를 벡터화 해줍니다. a가 딱 하나 존재합니다\n",
    "vector_for_char_a = np.zeros((vocab_size, 1))\n",
    "vector_for_char_a[char_to_ix['a']] = 1\n",
    "\n",
    "# hyperparameters\n",
    "hidden_size = 100\n",
    "# 알파벳은 26개가 존재\n",
    "seq_length = 25\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward, backward 모델을 만들어봅시다\n",
    "# model parameters\n",
    "# input->hidden, hidden->hidden, hidden->output의 weight들을 설정해줍니다\n",
    "# bias->hidden, bias->output의 bias 또한 임의로 설정해줍니다\n",
    "\n",
    "# input -> hidden state로 향하는 weight\n",
    "Wxh = np.random.randn(hidden_size, vocab_size) * 0.01\n",
    "# hiden -> next hidden state로 향하는 weight\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "# hidden -> output으로 향하는 weight\n",
    "Why = np.random.randn(vocab_size, hidden_size) * 0.01\n",
    "# bias -> hidden state의 bias\n",
    "bh = np.zeros((hidden_size, 1))\n",
    "# bias -> output으로 향하는 bias\n",
    "by = np.zeros((vocab_size, 1))\n",
    "\n",
    "\n",
    "# loss function을 정의해봅시다\n",
    "def lossFun(inputs, targets, hprev):\n",
    "    # xs : 1-hot encoding을 한 input character\n",
    "    # hs : hidden state out for 25 time steps\n",
    "    # ys ; target value\n",
    "    # ps : take the ys and convert them to nomarlized probability\n",
    "    xs, hs, ys, ps = {}, {}, {}, {}\n",
    "    # hidden prev를 그대로 사용합니다\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    \n",
    "    # initialize loss = 0\n",
    "    loss = 0\n",
    "    \n",
    "    # forward 과정\n",
    "    for t in range(len(inputs)):\n",
    "        \n",
    "        # input state 초기화\n",
    "        xs[t] = np.zeros((vocab_size,1))\n",
    "        xs[t][inputs[t]] = 1\n",
    "        # input -> hidden + hidden -> hidden forward\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state                                                                                                            \n",
    "        # unnormalized log probabilities\n",
    "        ys[t] = np.dot(Why, hs[t]) + by\n",
    "        # 다음 글자를 고를 확률\n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars                                                                                                              \n",
    "        # softmax(cross-entropy loss)\n",
    "        loss += -np.log(ps[t][targets[t],0])\n",
    "    \n",
    "    # backward(backpropagation)을 해봅니다\n",
    "    # np.zeros_like는 입력받는 배열의 형태와 같은 크기의 0을 반환합니다\n",
    "    # dWxh, dWhh, dWhy, dbh, dby, dhnext를 초기화\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    \n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # forward에서 얻은 확률을 토대로 가중치를 조절해줍니다\n",
    "        # collect ouput probability\n",
    "        dy = np.copy(ps[t])\n",
    "        # 1st gradient value를 추출\n",
    "        dy[targets[t]] -= 1\n",
    "        # compute output gradient - output times hidden states transpose\n",
    "        # Transpose를 적용하는 이유는 네트워크를 통해 오차를 뒤로 전파하는것으로\n",
    "        # 생각할 수 있습니다. n번째 레이어의 출력에서 오류에 대한 측정을 제공합니다\n",
    "        # error value constantly change every layer \n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        # derivative of output bias\n",
    "        dby += dy\n",
    "        # backpropagate into hidden layer\n",
    "        dh = np.dot(Why.T, dy) + dhnext\n",
    "        # tanh nonlinearity를 이용한 backpropation\n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh\n",
    "        # derivative of hidden bias\n",
    "        dbh += dhraw\n",
    "        # derivative of input to hidden layer\n",
    "        dWxh += np.dot(dhraw, xs[t].T)\n",
    "        # derivative of hiden layer to hidden layer\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "        dhnext = np.dot(Whh.T, dhraw)\n",
    "        \n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        # 엄청나게 큰 데이터(예를들어 성경)를 학습하다보면 학습을 계속함에 따라\n",
    "        # 기울기가 사라질 수 있습니다 (음의 무한대로 가거나, 양의 무한대로 가거나)\n",
    "        # 이를 방지하기 위해 numpy의 clip 함수를 써줍니다\n",
    "        # -5보다 작으면 -5로 고정, 5보다 크면 5로 고정, 그 사이는 그대로 나타냅니다\n",
    "        np.clip(dparam, -5, 5, out=dparam)\n",
    "    \n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "\n",
    "# 모델이 완성되었습니다 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " \n",
      ")'\"YTcNL' A$XwfSMQ$tf@K69,ALvKRt*?Jlow374oGY$vo6om9l9B nlub:%ybbW(xxSaX*xpnPxkDgcmq5QYV;$mFIm9,3WJsTdck$9x4r-.,XazXpzG3D-9e?%\n",
      "1Yn%;.\n",
      "2%'/t:y'bYlw5PxzMpquPHP9J@;qG5H!$\"ç3TG;JClj1,Y!'4%*-Wf'rQDNE.QY%oC \n",
      "----\n",
      "iter 0, loss: 109.550662\n",
      "----\n",
      " PylDzxMzT? MMeyjy8SOLaeT00B.4v33.o,xo:jfPszE13-' ked%0Mc?A-YzO8K222B%PW\"DpLE2,DsY2g;/:QEP7kV.wFcv7a?'RM kJwrK,iAç/'X/*5K)pj59yPKJ;Atli'(/JFmFXN:9--LGTwA/oWX0\"@SIkByz?xpJ:ç6dms*dDOd qXhNg$wiT(j7;sGdRm5 \n",
      "----\n",
      "iter 1000, loss: 85.759024\n",
      "----\n",
      "  pmltl se cleem tht tod a's kes more tug goherliigherh ree ho Had tre  couerSind an, thnhell sa,ig aomeun dtr ler hileco ckkatf lac im alr don taventhetn -e sk ro asre  thenm tohe a' im,  he me ad he. \n",
      "----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6d703b747c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;31m# forward seq_length characters through the net and fetch gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWxh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWhh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdWhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0msmooth_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.999\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ee18bbacefce>\u001b[0m in \u001b[0;36mlossFun\u001b[0;34m(inputs, targets, hprev)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# 다음 글자를 고를 확률\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# probabilities for next chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# softmax(cross-entropy loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#이부분은 실행부분입니다. 그냥 복붙해서 실행해보겠습니다\n",
    "\n",
    "#prediction, one full forward pass\n",
    "def sample(h, seed_ix, n):\n",
    "  \"\"\"                                                                                                                                                                                         \n",
    "  sample a sequence of integers from the model                                                                                                                                                \n",
    "  h is memory state, seed_ix is seed letter for first time step   \n",
    "  n is how many characters to predict\n",
    "  \"\"\"\n",
    "  #create vector\n",
    "  x = np.zeros((vocab_size, 1))\n",
    "  #customize it for our seed char\n",
    "  x[seed_ix] = 1\n",
    "  #list to store generated chars\n",
    "  ixes = []\n",
    "  #for as many characters as we want to generate\n",
    "  for t in range(n):\n",
    "    #a hidden state at a given time step is a function \n",
    "    #of the input at the same time step modified by a weight matrix \n",
    "    #added to the hidden state of the previous time step \n",
    "    #multiplied by its own hidden state to hidden state matrix.\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    #compute output (unnormalised)\n",
    "    y = np.dot(Why, h) + by\n",
    "    ## probabilities for next chars\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    #pick one with the highest probability \n",
    "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "    #create a vector\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    #customize it for the predicted char\n",
    "    x[ix] = 1\n",
    "    #add it to the list\n",
    "    ixes.append(ix)\n",
    "\n",
    "  txt = ''.join(ix_to_char[ix] for ix in ixes)\n",
    "  print('----\\n %s \\n----' % (txt, ))\n",
    "hprev = np.zeros((hidden_size,1)) # reset RNN memory  \n",
    "#predict the 200 next characters given 'a'\n",
    "sample(hprev,char_to_ix['a'],200)\n",
    "\n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad                                                                                                                \n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0                                                                                                                        \n",
    "while n<=1000*10:\n",
    "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "  # check \"How to feed the loss function to see how this part works\n",
    "  if p+seq_length+1 >= len(data) or n == 0:\n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory                                                                                                                                      \n",
    "    p = 0 # go from start of data                                                                                                                                                             \n",
    "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "  # forward seq_length characters through the net and fetch gradient                                                                                                                          \n",
    "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "  # sample from the model now and then                                                                                                                                                        \n",
    "  if n % 1000 == 0:\n",
    "    print ('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "    sample(hprev, inputs[0], 200)\n",
    "\n",
    "  # perform parameter update with Adagrad                                                                                                                                                     \n",
    "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
    "                                [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "    mem += dparam * dparam\n",
    "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update                                                                                                                   \n",
    "\n",
    "  p += seq_length # move data pointer                                                                                                                                                         \n",
    "  n += 1 # iteration counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "#   \n",
    "#   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # PROBABILITY THEORY\n",
    "---\n",
    "\n",
    "# NAIVE BAYES 정리\n",
    "\n",
    "![JPEG](http://uc-r.github.io/public/images/analytics/naive_bayes/naive_bayes_icon.png)\n",
    "\n",
    "# 사건 X가 발생한 경우 C의 확률을 나타냅니다\n",
    "- 사전에 발생한 사건의 확률을 토대로 앞으로 일어날 일을 예측\n",
    "\n",
    "### 선행조건 2가지\n",
    "- 1. DATASET의 각 단어가 독립임을 가정합니다\n",
    "- 2. CONDITIONAL INDEPENDENCE ASSUMPTION, 영향 또한 독립적으로 받습니다\n",
    "#   \n",
    "---\n",
    "\n",
    "# BACK-OF-WORDS\n",
    "- 나이츠 베이즈는 아래 그림처럼 단어의 등장 순서를 무시합니다\n",
    "- 따라서 스팸메일 분류기 혹은 영화 리뷰 분류같은, 순서가 상관없는 예측에서 유용하게 쓰입니다\n",
    "\n",
    "![JPEG](https://i.imgur.com/u5kdniF.png)\n",
    "---\n",
    "# LAPLACE SMOOTHING\n",
    "\n",
    "> 학습 데이터에 없는 단어가 등장할 때 분류를 하면, P가 0이 되는 문제가 발생합니다\n",
    "\n",
    "- 이를 방지하기 위해, 새로운 단어가 나오더라도 해당 빈도에 +1을 해줌으로써 \n",
    "- 확률이 0이 되는것을 막아줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  spam\n",
       "0  Go until jurong point, crazy.. Available only ...     0\n",
       "1                      Ok lar... Joking wif u oni...     0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3  U dun say so early hor... U c already then say...     0\n",
       "4  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 잘 작동이 안되는 코드입니다. 그냥 맛보기로만 봅시다.\n",
    "# 스팸 데이터셋을 불러옵니다\n",
    "# encoding을 해주지 않으면 읽어지지 않습니다\n",
    "spam = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
    "# 2열과 1열만 필요하니 두개만 불러옵니다\n",
    "# 2열에는 메일의 내용이, 1열에는 스팸, 비스팸 여부가 담겨있습니다\n",
    "spam = spam[['v2','v1']]\n",
    "# 각각 column의 이름을 sms, spam으로 바꿔줍니다\n",
    "spam.columns = ['sms', 'spam']\n",
    "# spam이면 1, ham이면 0으로 모두 바꿔줍니다\n",
    "spam['spam'].replace(['ham','spam'],[0,1],inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = spam['sms']\n",
    "y = spam['spam']\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.33)\n",
    "\n",
    "spam.head()\n",
    "\n",
    "## \n",
    "def train:\n",
    "    # 총 이메일 갯수를 0으로 초기화\n",
    "    total = 0\n",
    "    # 스팸메일 갯수를 0으로 초기화\n",
    "    numSpam = 0\n",
    "    # 이메일을 모두 돌려보면서\n",
    "    for emil in spam:\n",
    "        # 스팸이라 판정되면\n",
    "        if email.label == SPAM :\n",
    "            # 스팸에 1개추가\n",
    "            numSpam += 1\n",
    "        # 총이메일에 1개추가\n",
    "        total += 1\n",
    "        # 스팸이라 판별된 이메일을 body와 label로 조각냅니다\n",
    "        processEmail(email.body, email.label)\n",
    "    # 모든 메일 중 스팸일 확률\n",
    "    pSpam = numSpam/float(total)\n",
    "    # 모든 메일 중 스팸이 아닐 확률\n",
    "    pnotSpam = (total- numSpam)/float(total)\n",
    "    \n",
    "# 스팸, 비스팸을 판별\n",
    "def classify(email):\n",
    "    isSpam = pA * conditionalEmail(email, True) # P (A | B)\n",
    "    notSpam = pNotA * conditionalEmail(email, False) # P(¬A | B)  \n",
    "    return isSpam > notSpam\n",
    "\n",
    "## 나중에 완벽한 코드로 찾아뵙겠습니다 .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "#   \n",
    "#   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
